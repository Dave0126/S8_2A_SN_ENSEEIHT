{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TP7 - YOLO - Sujet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVz03XXMKMoz"
      },
      "source": [
        "# Détection d'objet : version simplifiée de YOLO\n",
        "\n",
        "<center> <img src=\"https://drive.google.com/uc?id=1V4aAS7K_Akj83apuMZ2vRjNvjgdgoOCh\" width=500></center>\n",
        "<caption><center> Pipeline de l'algorithme YOLO ([Redmon 2016]) </center></caption>\n",
        "\n",
        "Dans ce TP, nous allons tenter d'aller un peu plus loin que le TP précédent en considérant le problème plus complexe de la détection d'objet, c'est-à-dire de la localisation et la classification conjointe de tous les objets dans l'image ; pour cela nous allons implémenter une version simplifiée de YOLO. Cette version est considérée simplifiée car ne reprenant pas l'intégralité des éléments décrite dans l'article de Redmon (par exemple, sur le choix de l'optimiseur). Une des simplifications principales est également que nous ne considérerons **qu'un objet par cellule**.\n",
        "\n",
        "Pour rappel, l'idée de YOLO est de découper l'image en une grille de cellules et de réaliser une prédiction de plusieurs boîtes englobantes ainsi qu'une classification par cellule. La vidéo de la cellule suivante rappelle les concepts vus en cours sur YOLO et la détection d'objet en général.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-8wH0b0jquq"
      },
      "source": [
        "from IPython.display import IFrame\n",
        "IFrame(\"https://video.polymny.studio/?v=012cd29c-db98-458f-80d3-6cc5c1da9be3/\", width=640, height=360)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nsjid8knt6GZ"
      },
      "source": [
        "Récupération des données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvf5aZetUIE0"
      },
      "source": [
        "!git clone https://github.com/axelcarlier/wildlife.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZu_3SudL_ll"
      },
      "source": [
        "\n",
        "## Fonctions utiles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hw4t0vv5uAYv"
      },
      "source": [
        "Définition des différentes variables utiles pour la suite"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79AGCFLvMUlw"
      },
      "source": [
        "IMAGE_SIZE = 64 # Dimension des images en entrée du réseau\n",
        "CELL_PER_DIM = 8 # Nombre de cellules en largeur et en hauteur\n",
        "BOX_PER_CELL = 1 # Nombre d'objets par cellule\n",
        "NB_CLASSES = 4 # Nombre de classes du problème\n",
        "PIX_PER_CELL = round(IMAGE_SIZE/CELL_PER_DIM)\n",
        "\n",
        "CLASS_LABELS = ['buffalo', 'elephant', 'rhino', 'zebra']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chargement des données"
      ],
      "metadata": {
        "id": "ynBA-Pn5RUmY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On charge les images dans la dimension demandée, dans un tenseur $x$. Pour les labels, on ne les structure pas directement dans le format YOLO, mais on les place dans une liste de liste de listes : la longueur de la liste parente est celle du nombre d'images de la base, celle de la liste intermédiaire est celle du nombre d'objets d'une image donnée, et enfin la liste de plus bas niveau a une longueur 5 et contiendra les coordonnées de boîte englobante et les labels de classe associés. "
      ],
      "metadata": {
        "id": "qyJTpIjFTGii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import math\n",
        "\n",
        "\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import glob, os, sys\n",
        "\n",
        "for file in glob.glob(\"*.txt\"):\n",
        "    print(file)\n",
        "\n",
        "def load_data_detection(ds_path):\n",
        "  \n",
        "  y_paths = []\n",
        "  # Détermination du nombre d'images total\n",
        "  for c in CLASS_LABELS:\n",
        "    path = ds_path + c + '/'\n",
        "    for file in os.listdir(path):\n",
        "      if file.endswith('.txt'):\n",
        "          y_paths.append(os.path.join(path, file))\n",
        "\n",
        "  dataset_size = len(y_paths)\n",
        "  \n",
        "  # Préparation des structures de données pour x et y\n",
        "  x = np.zeros((dataset_size, IMAGE_SIZE, IMAGE_SIZE, 3))\n",
        "  y = []\n",
        "\n",
        "  for i in range(len(y_paths)):\n",
        "    text_path = y_paths[i]\n",
        "    img_path = text_path[:-3] + 'jpg'\n",
        "    \n",
        "    if not os.path.exists(img_path):\n",
        "      img_path = text_path[:-3] + 'JPG'\n",
        "\n",
        "    # Lecture de l'image : on va remplir la variable x\n",
        "    # Lecture de l'image\n",
        "    img = Image.open(img_path)\n",
        "    # Mise à l'échelle de l'image\n",
        "    img = img.resize((IMAGE_SIZE, IMAGE_SIZE), Image.ANTIALIAS)\n",
        "    # Remplissage de la variable x\n",
        "    x[i] = np.asarray(img, dtype=np.int32)\n",
        "\n",
        "    # Texte : coordonnées de boîtes englobantes pour remplir y\n",
        "    boxes = []\n",
        "    # Texte : coordonnées de boîtes englobantes pour remplir y\n",
        "    text_file = open(text_path, \"r\")\n",
        "    # Récupération des lignes du fichier texte\n",
        "    rows = text_file.read().split('\\n')\n",
        "    # Parcours de chaque ligne\n",
        "    for row in rows:\n",
        "      if row != '':\n",
        "        # Séparation des différentes informations\n",
        "        row = list(row.split(' '))\n",
        "        box = []\n",
        "        # réorganisation : les 4 coordonnées de boîte englobantes (castées en flottants) d'abord\n",
        "        for r in row[1:]:\n",
        "          box.append(float(r))\n",
        "          \n",
        "        box_normal = [box[0]-box[2]/2, box[1]-box[3]/2, box[0]+box[2]/2, box[1]+box[3]/2]  \n",
        "\n",
        "        # Puis le label de classe (casté en entier) à la suite\n",
        "        box.append(int(row[0]))\n",
        "        boxes.append(box)\n",
        "\n",
        "    y.append(boxes)\n",
        "  return x, y\n",
        "\n",
        "# Chemin vers la base de données\n",
        "ds_path = \"./wildlife/\"  \n",
        "x ,y = load_data_detection(ds_path)\n"
      ],
      "metadata": {
        "id": "gStC1HJXTFe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Affichage des données\n",
        "\n",
        "Le code ci-dessous vous permettra d'afficher les images ainsi que leurs boîtes englobantes associées. On peut spécifier l'id d'une image en particulier ou, si l'on en spécifie pas, visualiser une image aléatoire."
      ],
      "metadata": {
        "id": "1HQNMBwSDhXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.special import softmax\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def print_data_detection(x, y, id=None, classes=CLASS_LABELS, image_size=IMAGE_SIZE):\n",
        "  if id==None:\n",
        "    # Tirage aléatoire d'une image dans la base\n",
        "    num_img = np.random.randint(x.shape[0]) \n",
        "  else:\n",
        "    num_img = id\n",
        "\n",
        "  img = x[num_img]\n",
        "  if np.max(img) > 1:\n",
        "    img = img/255\n",
        "  boxes = y[num_img]\n",
        "\n",
        "  colors = [\"blue\", \"yellow\", \"red\", \"orange\"] # Différentes couleurs pour les différentes classes\n",
        "\n",
        "  # Affichage de l'image\n",
        "  plt.imshow(img)\n",
        "  for box in boxes:\n",
        "\n",
        "    # Détermination de la classe\n",
        "    class_id = box[4]\n",
        "    \n",
        "    # Détermination des extrema de la boîte englobante\n",
        "    p_x = [(box[0]-box[2]/2) * IMAGE_SIZE, (box[0]+box[2]/2) * IMAGE_SIZE]\n",
        "    p_y = [(box[1]-box[3]/2) * IMAGE_SIZE, (box[1]+box[3]/2) * IMAGE_SIZE]\n",
        "\n",
        "    # Affichage de la boîte englobante, dans la bonne couleur\n",
        "    plt.plot([p_x[0], p_x[0]],p_y,color=colors[class_id])\n",
        "    plt.plot([p_x[1], p_x[1]],p_y,color=colors[class_id])\n",
        "    plt.plot(p_x,[p_y[0],p_y[0]],color=colors[class_id])\n",
        "    plt.plot(p_x,[p_y[1],p_y[1]],color=colors[class_id], label=classes[class_id])\n",
        "    #plt.title(\"Vérité Terrain : Image {}\".format(num_img, classes[class_id]))\n",
        "  \n",
        "  plt.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\n",
        "  plt.axis('off')\n",
        "  plt.show()  \n",
        "\n",
        "\n",
        "print_data_detection(x, y, id=22)\n"
      ],
      "metadata": {
        "id": "gK0Xl-CgDjjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Écriture des labels au format YOLO"
      ],
      "metadata": {
        "id": "77EZpBu8F1Y2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les deux fonctions ci-dessous sont essentielles car elles permettent de convertir les boîtes englobantes dans le format adopté par YOLO (voir la section Modèle un peu plus bas), mais également de faire l'opération inverse afin d'interpréter la sortie du réseau.\n",
        "\n",
        "Notez que la fonction *get_box_from_yolo* intègre dans les boîtes englobantes une information supplémentaire par rapport aux données chargées initialement : la probabilité de présence associée à la boîte englobante."
      ],
      "metadata": {
        "id": "JOVhY98p5WDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "from scipy.special import expit, softmax\n",
        "\n",
        "\n",
        "def set_box_for_yolo(y, num_classes=NB_CLASSES, image_size=IMAGE_SIZE, cell_size=PIX_PER_CELL):\n",
        "  nb_cells_per_dim = round(image_size/cell_size)\n",
        "\n",
        "  y_YOLO = np.zeros((len(y), nb_cells_per_dim, nb_cells_per_dim, 1 + 4 + num_classes))\n",
        "\n",
        "  for i in range(len(y)):\n",
        "    for box in y[i]:\n",
        "      # Coordonnées du centre de la boîte englobante dans le repère image\n",
        "      cx, cy = box[0] * image_size, box[1] * image_size\n",
        "      # Détermination des indices de la cellule dans laquelle tombe le centre\n",
        "      ind_x, ind_y = int(cx // cell_size), int(cy // cell_size)\n",
        "      # YOLO : \"The (x, y) coordinates represent the center of the box relative to the bounds of the grid cell.\"\n",
        "      # On va donc calculer les coordonnées du centre relativement à la cellule dans laquelle il se situe\n",
        "      y_YOLO[i, ind_x, ind_y, 1] = (cx - ind_x * cell_size) / cell_size\n",
        "      y_YOLO[i, ind_x, ind_y, 2] = (cy - ind_y * cell_size) / cell_size\n",
        "      # Largeur et hauteur de boîte\n",
        "      y_YOLO[i, ind_x, ind_y, 3] = box[2]\n",
        "      y_YOLO[i, ind_x, ind_y, 4] = box[3]\n",
        "\n",
        "      # Indice de confiance de la boîte englobante pour la cellule correspondante\n",
        "      y_YOLO[i, ind_x, ind_y, 0] = 1\n",
        "      # On range les probabilités de classe à la fin du vecteur ([ Présence ; cx ; cy ; w ; h ; CLASSES])\n",
        "      y_YOLO[i, ind_x, ind_y, 5:] = to_categorical(box[4], num_classes=num_classes)\n",
        "\n",
        "  return y_YOLO\n",
        "\n",
        "# Si mode = 'pred', il s'agit d'une prédiction du réseau, il faut alors utiliser la fonction sigmoide\n",
        "# pour obtenir la présence prédite, et la fonction softmax pour obtenir les probabilités de classe \n",
        "def get_box_from_yolo(y_YOLO, mode=None, confidence_threshold=0.5, num_classes=NB_CLASSES, image_size=IMAGE_SIZE, cell_size=PIX_PER_CELL):\n",
        "  nb_cells_per_dim = round(image_size/cell_size)\n",
        "\n",
        "  y = []\n",
        "  for i in range(y_YOLO.shape[0]):\n",
        "    boxes = []\n",
        "    for ind_x in range(cell_size):\n",
        "      for ind_y in range(cell_size):\n",
        "        if mode == 'pred':\n",
        "          presence = expit(y_YOLO[i, ind_x, ind_y, 0])\n",
        "          classes_probabilities = softmax(y_YOLO[i, ind_x, ind_y, 5:])\n",
        "          # coords = expit(y_YOLO[i, ind_x, ind_y, 1:5])\n",
        "        else:\n",
        "          presence = y_YOLO[i, ind_x, ind_y, 0]\n",
        "          classes_probabilities = y_YOLO[i, ind_x, ind_y, 5:]\n",
        "\n",
        "        coords = y_YOLO[i, ind_x, ind_y, 1:5]\n",
        "        if presence > confidence_threshold:\n",
        "\n",
        "          box = []\n",
        "          box.append((coords[0] * cell_size + ind_x * cell_size) / image_size)\n",
        "          box.append((coords[1] * cell_size + ind_y * cell_size) / image_size)\n",
        "          box.append(coords[2])\n",
        "          box.append(coords[3])\n",
        "          box.append(np.argmax(y_YOLO[i, ind_x, ind_y, 5:]))\n",
        "          box.append(presence)\n",
        "          boxes.append(box)\n",
        "\n",
        "    y.append(boxes)\n",
        "\n",
        "  return y \n",
        "\n",
        "# On s'assure de pouvoir passer d'une représentation à l'autre sans altérer les données\n",
        "print(y[:2])\n",
        "print(get_box_from_yolo(set_box_for_yolo(y[:2])))"
      ],
      "metadata": {
        "id": "vYbQVxZXGAET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Augmentation de données"
      ],
      "metadata": {
        "id": "AVXo7WaCBNWT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il nous faut une version récente de la librairie Albumentations pour pouvoir profiter des fonctionnalités lies aux boîtes englobantes."
      ],
      "metadata": {
        "id": "vgXVpt6z6jRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall opencv-python-headless==4.5.5.62\n",
        "!pip install opencv-python-headless==4.1.2.30\n",
        "!pip install -q -U albumentations\n",
        "!echo \"$(pip freeze | grep albumentations) is successfully installed\""
      ],
      "metadata": {
        "id": "_anbyrRRBRK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans la cellule ci-dessous, il vous faudra intégrer les augmentations que vous aurez choisi. **Attention, ne faites cette partie que dans un second temps, lorsque vous aurez une première version du réseau qui fonctionnera !**\n",
        "\n",
        "Aidez-vous de [cette page](https://albumentations.ai/docs/getting_started/transforms_and_targets/) pour déterminer des augmentations qui peuvent fonctionner."
      ],
      "metadata": {
        "id": "pXIF0AMf6pqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from albumentations import (Compose, HorizontalFlip)\n",
        "import albumentations as A\n",
        "\n",
        "AUGMENTATIONS_TRAIN = Compose([\n",
        "    #### A COMPLETER, MAIS SEULEMENT LORSQUE VOUS AVEZ UN RESEAU QUI (SUR-)APPREND !\n",
        "    # HorizontalFlip(p=0.5), \n",
        "    # ...\n",
        "], bbox_params=A.BboxParams(format='yolo'))"
      ],
      "metadata": {
        "id": "2-z8AmRpCdLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "L'objet Sequence défini ci-dessous nous permettra la mise en batch de nos données. On est obligé d'avoir recours à cette solution (plutôt qu'un ImageDataGenerator comme lors du TP3) car ici les augmentations à appliquer altèrent également les labels, ce qui n'est pas supporté par un ImageDataGenerator."
      ],
      "metadata": {
        "id": "Q2oSuKEV7DyU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import Sequence\n",
        "\n",
        "class YOLOSequence(Sequence):\n",
        "    # Initialisation de la séquence avec différents paramètres\n",
        "    def __init__(self, x_set, y_set, batch_size,augmentations):\n",
        "        self.x, self.y = x_set, y_set\n",
        "        self.batch_size = batch_size\n",
        "        self.augment = augmentations\n",
        "        self.indices1 = np.arange(x_set.shape[0], dtype='int') \n",
        "        np.random.shuffle(self.indices1) # Les indices permettent d'accéder\n",
        "        # aux données et sont randomisés à chaque epoch pour varier la composition\n",
        "        # des batches au cours de l'entraînement\n",
        "\n",
        "    # Fonction calculant le nombre de pas de descente du gradient par epoch\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
        "   \n",
        "\n",
        "    # Il y a des problèmes d'arrondi dans les conversions de boîtes englobantes \n",
        "    # internes à la librairie Albumentations\n",
        "    # Pour les contourner, si les boîtes sont trop proches des bords, on les érode un peu\n",
        "    def erode_bounding_box(self, box, epsilon = 0.02):\n",
        "        eroded_box = []\n",
        "        \n",
        "        xmin = max(box[0] - box[2]/2, epsilon)\n",
        "        ymin = max(box[1] - box[3]/2, epsilon)\n",
        "        xmax = min(box[0] + box[2]/2, 1-epsilon)\n",
        "        ymax = min(box[1] + box[3]/2, 1-epsilon)\n",
        "        \n",
        "        cx = xmin + (xmax - xmin)/2\n",
        "        cy = ymin + (ymax - ymin)/2\n",
        "        width = xmax - xmin\n",
        "        height = ymax - ymin\n",
        "        \n",
        "        eroded_box = [cx, cy, width, height, box[4]]\n",
        "        return eroded_box\n",
        "\n",
        "    # Application de l'augmentation de données à chaque image du batch et aux\n",
        "    # boîtes englobantes associées\n",
        "    def apply_augmentation(self, bx, by):\n",
        "\n",
        "        batch_x = np.zeros((bx.shape[0], IMAGE_SIZE, IMAGE_SIZE, 3))\n",
        "        batch_y = []\n",
        "\n",
        "        # Pour chaque image du batch\n",
        "        for i in range(len(bx)):\n",
        "            boxes = []\n",
        "            # Erosion des boîtes englobantes\n",
        "            for box in by[i]:\n",
        "              boxes.append(self.erode_bounding_box(box))\n",
        "\n",
        "            # Application de l'augmentation à l'image et aux boîtes englobantes\n",
        "            transformed = self.augment(image=bx[i].astype('float32'), bboxes=boxes)\n",
        "            batch_x[i] = transformed['image']\n",
        "            batch_y_transformed = transformed['bboxes']\n",
        "            batch_y.append(batch_y_transformed)\n",
        "\n",
        "        return batch_x, batch_y\n",
        "\n",
        "    # Fonction appelée à chaque nouveau batch : sélection et augmentation des données\n",
        "    def __getitem__(self, idx):\n",
        "        # Sélection des indices des données du prochain batch\n",
        "        batch_indices = self.indices1[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        # Récupération des données puis des labels du batch\n",
        "        batch_x = self.x[batch_indices]\n",
        "        batch_boxes = [self.y[item] for item in list(batch_indices)]\n",
        "        # Application de l'augmentation de données\n",
        "        batch_x_aug, batch_boxes_aug = self.apply_augmentation(batch_x, batch_boxes)\n",
        "        \n",
        "        # Préparation des données pour le réseau :\n",
        "        # Normalisation des entrées\n",
        "        batch_x_aug = batch_x_aug/255\n",
        "        # Passage des sorties au format YOLO\n",
        "        batch_y_YOLO = set_box_for_yolo(batch_boxes_aug)\n",
        " \n",
        "        return np.array(batch_x_aug), batch_y_YOLO\n",
        "\n",
        "    # Fonction appelée à la fin d'un epoch ; on randomise les indices d'accès aux données\n",
        "    def on_epoch_end(self):\n",
        "        np.random.shuffle(self.indices1)\n",
        "        \n"
      ],
      "metadata": {
        "id": "yALbgasfBYOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instanciation d'une Sequence\n",
        "train_gen = YOLOSequence(x[:1], y[:1], 1, augmentations=AUGMENTATIONS_TRAIN)\n",
        "\n",
        "# Pour tester la séquence, nous sélectionnons les éléments du premier batch et les affichons\n",
        "batch_x, batch_y = train_gen.__getitem__(0)\n",
        "\n",
        "print_data_detection(batch_x, get_box_from_yolo(batch_y))"
      ],
      "metadata": {
        "id": "FekjKk5rDcrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implémentation de YOLO"
      ],
      "metadata": {
        "id": "FDkeWyl0TCJ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modèle"
      ],
      "metadata": {
        "id": "tT7sNJTC120-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrEtJvKAwsB2"
      },
      "source": [
        "\n",
        "<center> <img src=\"https://drive.google.com/uc?id=1_wXc_gTIAr37STaxu3chq1EEjVSKv6a5\" width=500></center>\n",
        "<caption><center> Illustration de la couche de sortie de YOLO. </center></caption>\n",
        "\n",
        "Le modèle que je vous propose ci-dessous n'est qu'une possibilité parmi beaucoup d'autres. \n",
        "A vous de compléter la dernière couche pour avoir une sortie de la bonne dimension.\n",
        "\n",
        "**Remarque importante** : comme le tenseur de sortie de YOLO est un peu complexe à manipuler, on choisit ici de regrouper l'ensemble des prédictions dans une seule et même sortie, ce qui nous oblige à utiliser la même fonction d'activation pour toutes nos sorties. On utilisera donc l'activation **linéaire** pour toutes ces sorties. On appliquera les fonctions sigmoïde et softmax pour les sorties \"présence\" et \"probablités de classe\" directement dans la fonction de coût !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3VZsE7EmRPC"
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Reshape, Dropout, Input\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "\n",
        "def create_model_YOLO(input_shape=(64, 64, 3)):\n",
        "  input_layer = Input(shape=input_shape)\n",
        "\n",
        "  conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(input_layer)\n",
        "  conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
        "  pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "  \n",
        "  conv2 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
        "  conv2 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
        "  pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "  \n",
        "  conv3 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
        "  conv3 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
        "  pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "  conv4 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
        "  ### A COMPLETER\n",
        "  output = ...\n",
        "\n",
        "  model = Model(input_layer, output)\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGi3Yz8Tm4li"
      },
      "source": [
        "model = create_model_YOLO()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fonction de coût"
      ],
      "metadata": {
        "id": "Z7QasIJE2wiG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuCP3Ju8Uo9e"
      },
      "source": [
        "<center> <img src=\"https://drive.google.com/uc?id=1Fbt_Wh_BqZj8Pwt3-04325ItCkQp5G9X\" style=\"width:500;height:300px;\"></center>\n",
        "<caption><center> Détail de la fonction de perte définie dans l'article YOLO v1 </center></caption>\n",
        "\n",
        "Nous arrivons maintenant à la partie délicate de l'implémentation de YOLO : la définition de la fonction de coût à utiliser.\n",
        "\n",
        "Comme nous l'avons vu dans le TP4, lorsque l'on écrit une fonction de coût personnalisée en Keras, il est nécessaire d'utiliser uniquement les fonctions présentes sur la page suivante : \n",
        "https://keras.rstudio.com/articles/backend.html\n",
        "\n",
        "En effet cette fonction de coût qui sera appelée pendant l'entraînement traitera des tenseurs, et non des tableau *numpy*. On doit donc utiliser la librairie Tensorflow qui permet de manipuler les tenseurs.\n",
        "\n",
        "Une partie essentielle de la fonction est déjà écrite : celle qui permet de séparer les données des cellules dites \"vide\" (la vérité terrain ne contient pas de boîte englobante) des \"non vides\".\n",
        "\n",
        "Le détail de la fonction de coût est indiqué ci-dessus : dans l'article $\\lambda_{\\text{coord}} = 5$ et $\\lambda_{\\text{noobj}} = 0.5$. Les $x_i$, $y_i$, $w_i$, $h_i$ correspondent aux coordonnées d'une boîte englobante, $C_i$ correspond à la probabilité de présence d'un objet dans la cellule, et les $p_i(c)$ sont les probabilités de classe.\n",
        "\n",
        "A vous de compléter l'expression des sous-fonctions de la fonction de coût (les fonctions *K.sum*, *K.square*, *K.sigmoid* et *K.softmax* devraient vous suffire !). **N'oubliez pas d'appliquer une sigmoïde aux présences ($C_i$) et une softmax aux probabilités de classe $p_i$) !!**\n",
        "\n",
        "**NB : cette implémentation de la fonction de coût est très simplifiée et prend en compte le fait qu'il n'y a qu'une seule boîte englobante par cellule.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uS91oePKnE_K"
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "# Définition de la fonction de perte YOLO\n",
        "def YOLOss(lambda_coord, lambda_noobj, batch_size):\n",
        "\n",
        "    # Partie \"verte\" : sous-partie concernant l'indice de confiance et les \n",
        "    # probabilités de classe dans le cas où une boîte est présente dans la cellule\n",
        "    def box_loss(y_true, y_pred):\n",
        "      ### A COMPLETER\n",
        "      return ...\n",
        "\n",
        "    # Partie \"bleue\" : sous-partie concernant les coordonnées de boîte englobante \n",
        "    # dans le cas où une boîte est présente dans la cellule\n",
        "    def coord_loss(y_true, y_pred):\n",
        "      ### A COMPLETER\n",
        "      return ...\n",
        "\n",
        "\n",
        "    # Partie \"rouge\" : sous-partie concernant l'indice de confiance  \n",
        "    # dans le cas où aucune boîte n'est présente dans la cellule\n",
        "    def nobox_loss(y_true, y_pred):\n",
        "      ### A COMPLETER\n",
        "      return ...\n",
        "\n",
        "\n",
        "    def YOLO_loss(y_true, y_pred):\n",
        "\n",
        "      # On commence par reshape les tenseurs de bs x S x S x (5B+C) à (bsxSxS) x (5B+C)\n",
        "      y_true = K.reshape(y_true, shape=(-1, 9))\n",
        "      y_pred = K.reshape(y_pred, shape=(-1, 9))\n",
        "\n",
        "      # On cherche (dans les labels y_true) les indices des cellules pour lesquelles au moins la première boîte englobante est présente\n",
        "      not_empty = K.greater_equal(y_true[:, 0], 1)      \n",
        "      indices = K.arange(0, K.shape(y_true)[0])\n",
        "      indices_notempty_cells = indices[not_empty]\n",
        "\n",
        "      empty = K.less_equal(y_true[:, 0], 0)\n",
        "      indices_empty_cells = indices[empty]\n",
        "\n",
        "      # On sépare les cellules de y_true et y_pred avec ou sans boîte englobante\n",
        "      y_true_notempty = K.gather(y_true, indices_notempty_cells)\n",
        "      y_pred_notempty = K.gather(y_pred, indices_notempty_cells)\n",
        "\n",
        "      y_true_empty = K.gather(y_true, indices_empty_cells)\n",
        "      y_pred_empty = K.gather(y_pred, indices_empty_cells)\n",
        "\n",
        "      return (box_loss(y_true_notempty, y_pred_notempty) + lambda_coord*coord_loss(y_true_notempty, y_pred_notempty) + lambda_noobj*nobox_loss(y_true_empty, y_pred_empty))/batch_size\n",
        "\n",
        "   \n",
        "    # Return a function\n",
        "    return YOLO_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Apprentissage"
      ],
      "metadata": {
        "id": "urf1W1nl22EP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comme d'habitude, on sépare nos données en plusieurs ensembles (ici apprentissage et validation suffiront)."
      ],
      "metadata": {
        "id": "J9nL1qrv8o1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Séparation des données en ensemble de validation et d'apprentissage\n",
        "indices = np.arange(x.shape[0], dtype='int') \n",
        "np.random.seed(1)\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "x_train = x[indices[:1355]]\n",
        "y_train = [y[i] for i in indices[:1355]]\n",
        "\n",
        "x_val = x[indices[1355:]]\n",
        "y_val = [y[i] for i in indices[1355:]]\n",
        "\n",
        "y_val_YOLO = set_box_for_yolo(y_val)\n"
      ],
      "metadata": {
        "id": "wsW6jpYsvIK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prenez le temps de tester votre modèle et votre fonction de coût, ainsi que vos réglages d'hyperparamètres, en sur-apprenant sur une image d'abord, puis sur un batch d'images. Entraînez votre réseau et visualisez ses prédictions sur les données d'entraînement, puis de validation, pour obtenir une intuition sur les valeurs de *loss* permettant d'obtenir des résultats \"acceptables\"."
      ],
      "metadata": {
        "id": "_42Z4gjN8xK2"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91QkqtUCZc78"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "batch_size=16\n",
        "model = create_model_YOLO()\n",
        "### A COMPLETER\n",
        "learning_rate = ...\n",
        "opt = Adam(learning_rate=learning_rate)  \n",
        "\n",
        "# Instanciation de la séquence pour préparer les données et, plus tard, \n",
        "train_gen = YOLOSequence(x_train, y_train, batch_size, augmentations=AUGMENTATIONS_TRAIN)\n",
        "\n",
        "# Comme l'entraînement est instable, on déclenche une sauvegarde du modèle à chaque fois que\n",
        "# la perte de validation atteint un nouveau minimum\n",
        "model_saver = ModelCheckpoint('tmp/best_weights', monitor='val_loss', verbose=1, save_weights_only=True, save_best_only=True, mode='min')\n",
        "\n",
        "loss=[YOLOss(5, 0.5, batch_size)]\n",
        "\n",
        "model.compile(loss=loss,\n",
        "              optimizer=opt)\n",
        "\n",
        "history = model.fit(train_gen,\n",
        "              epochs=150,\n",
        "              batch_size=batch_size,          \n",
        "              validation_data=(x_val/255, y_val_YOLO),\n",
        "              callbacks = [model_saver])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test et affichage des résultats"
      ],
      "metadata": {
        "id": "q-coL0Hx24Ei"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIaImTjf1fvF"
      },
      "source": [
        "#### Test de la version à la fin de l'entrainement"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sur l'ensemble d'apprentissage**"
      ],
      "metadata": {
        "id": "lHD3nVgG2-G4"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjPnyo6G1b1W"
      },
      "source": [
        "y_pred = model.predict(x_train/255)\n",
        "y_pred_YOLO = get_box_from_yolo(y_pred, confidence_threshold=0.5, mode='pred')\n",
        "print_data_detection(x_train, y_pred_YOLO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Une fois les prédictions effectuées, vous pouvez pour aller plus rapidement uniquement relancer l'affichae aléatoire d'un seul résultat."
      ],
      "metadata": {
        "id": "3EmVROimOQml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print_data_detection(x_train, y_pred_YOLO)"
      ],
      "metadata": {
        "id": "sPZeZxIRg_M1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sur l'ensemble de validation**"
      ],
      "metadata": {
        "id": "raKF5JGC3B88"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5MKydNv1djI"
      },
      "source": [
        "y_pred = model.predict(x_val/255)\n",
        "y_pred_YOLO = get_box_from_yolo(y_pred, confidence_threshold=0.5, mode='pred')\n",
        "print_data_detection(x_val, y_pred_YOLO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_data_detection(x_val, y_pred_YOLO)"
      ],
      "metadata": {
        "id": "gbsnVJ6_0E3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqMHwVaJ1iyN"
      },
      "source": [
        "#### Test de la meilleure version sauvegardée"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La cellule ci-dessous vous permettra de charger les poids sauvegardés lorsque la meilleur performance a été atteinte sur l'ensemble de validation pendant l'entraînement."
      ],
      "metadata": {
        "id": "F09SWs1n9iD8"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRjn1SLn0JL4"
      },
      "source": [
        "model.load_weights('tmp/best_weights')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sur l'ensemble d'apprentissage**"
      ],
      "metadata": {
        "id": "g66MczLI3GGL"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfytX2yC1AdY"
      },
      "source": [
        "y_pred = model.predict(x_train/255)\n",
        "y_pred_YOLO = get_box_from_yolo(y_pred, confidence_threshold=0.5, mode='pred')\n",
        "print_data_detection(x_train, y_pred_YOLO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_data_detection(x_train, y_pred_YOLO)"
      ],
      "metadata": {
        "id": "uXr2p3MHx_hF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sur l'ensemble de validation**"
      ],
      "metadata": {
        "id": "2elJjjts3JtD"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBiTzmyu0QqH"
      },
      "source": [
        "y_pred = model.predict(x_val/255)\n",
        "y_pred_YOLO = get_box_from_yolo(y_pred, confidence_threshold=0.3, mode='pred')\n",
        "print_data_detection(x_val, y_pred_YOLO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_data_detection(x_val, y_pred_YOLO)"
      ],
      "metadata": {
        "id": "6YkUFRQ70M3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Si vous êtes rapide** \n",
        "\n",
        "Une amélioration possible pourrait être d'inclure une étape supplémentaire de suppression des prédictions \"non maximales\" (*non-max suppression*) pour se débarasser des boîtes redondantes, comme illustré sur la figure ci-dessous :\n",
        "\n",
        "<center> <img src=\"https://drive.google.com/uc?id=1XDpmffe_x_gDvsQZ_9sr6J5AuJPuSW0B\" width=300>\n",
        "<img src=\"https://drive.google.com/uc?id=1b9QgSFQlzOA7aJIbNc2Kl_eEMRDY0pQm\" width=300>\n",
        "</center>\n",
        "\n",
        "Pour cela, référez-vous au cours, il faut procéder de la manière suivante. Une fois les boîtes présentant un indice de confiance inférieur à un seuil (que nous avons fixé à $0.5$ plus tôt dans le TP) éliminées, on sélectionne la boîte englobante d'indice de confiance maximal $b_{max}$. Puis on parcourt l'ensemble des autres prédictions, et on élimine celles associées à la même classe qui présentent une intersection sur union avec $b_{max}$ supérieure à un second seuil (que, soyons honnêtes, on prend également souvent égal à $0.5$).\n",
        "\n",
        "On procède ainsi jusqu'à avoir visité toutes les boîtes !\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "T1ZZ1P4nOe3F"
      }
    }
  ]
}